{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install azure-ai-textanalytics"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: azure-ai-textanalytics in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (5.3.0)\nRequirement already satisfied: azure-core<2.0.0,>=1.24.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-textanalytics) (1.27.1)\nRequirement already satisfied: azure-common~=1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-textanalytics) (1.1.28)\nRequirement already satisfied: isodate<1.0.0,>=0.6.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-textanalytics) (0.6.1)\nRequirement already satisfied: typing-extensions>=4.0.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-textanalytics) (4.6.3)\nRequirement already satisfied: requests>=2.18.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2.31.0)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2023.5.7)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1714937815422
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: nltk in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (3.8.1)\nRequirement already satisfied: click in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from nltk) (8.0.4)\nRequirement already satisfied: joblib in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from nltk) (1.2.0)\nRequirement already satisfied: regex>=2021.8.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from nltk) (2024.4.28)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from nltk) (4.65.0)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1714938700677
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting opencv-python\n  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from opencv-python) (1.25.0)\nInstalling collected packages: opencv-python\nSuccessfully installed opencv-python-4.9.0.80\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1714938925329
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "cognitive_key ='LSRr0its8c1K8iLgoJCqOL6bRlcTpHana1r8n53KKXn5rbMn1RDqBh9Gg13fIGZ7qhwUSOCS6QcjACDbV6Dx1Q=='\n",
        "cognitive_endpoint='https://jmpkey.documents.azure.com:443/'\n",
        "\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "from azure.ai.textanalytics import TextAnalyticsClient\n",
        "\n",
        "credential=AzureKeyCredential(cognitive_key)\n",
        "text_analytics_client=TextAnalyticsClient(endpoint=cognitive_endpoint, credential=credential)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1714963470696
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from textblob import TextBlob\n",
        "\n",
        "def analyze_sentiment(comment_texts):\n",
        "    sentiments = []\n",
        "    for text in comment_texts:\n",
        "        blob = TextBlob(text)\n",
        "        sentiments.append(blob.sentiment.polarity)\n",
        "    return sentiments\n",
        "\n",
        "# Example usage:\n",
        "comment_texts = [\"This movie was excellent\", \"The plot was boring and predictable\"]\n",
        "sentiments = analyze_sentiment(comment_texts)\n",
        "print(sentiments)\n",
        "\n",
        "# Azure Cosmos DB settings\n",
        "account_name = 'jmpkey'\n",
        "account_key = 'LSRr0its8c1K8iLgoJCqOL6bRlcTpHana1r8n53KKXn5rbMn1RDqBh9Gg13fIGZ7qhwUSOCS6QcjACDbV6Dx1Q=='\n",
        "table_name = 'SampleContainer'\n",
        "ENDPOINT = 'https://jmpkey.documents.azure.com:443/'\n",
        "\n",
        "# Facebook API settings\n",
        "facebook_app_id = '458826160015583'\n",
        "facebook_app_secret = '●●●●●●●●'\n",
        "\n",
        "def get_facebook_video_comments(video_link):\n",
        "    # Get Facebook access token\n",
        "    access_token = requests.get(f'https://graph.facebook.com/oauth/access_token?client_id={facebook_app_id}&client_secret={facebook_app_secret}&grant_type=client_credentials').json()['access_token']\n",
        "\n",
        "    # Get video comments using Facebook API\n",
        "    comments = requests.get(f'https://graph.facebook.com/{video_link}/comments?access_token={access_token}').json()['data']\n",
        "\n",
        "    # Extract text from comments\n",
        "    comment_texts = [comment['message'] for comment in comments]\n",
        "\n",
        "    return comment_texts\n",
        "\n",
        "def analyze_sentiment(comment_texts):\n",
        "    sentiments = []\n",
        "    for text in comment_texts:\n",
        "        blob = TextBlob(text)\n",
        "        sentiments.append(blob.sentiment.polarity)\n",
        "    return sentiments\n",
        "\n",
        "def store_sentiments_in_cosmosdb(sentiments):\n",
        "    table_service = TableService(account_name, account_key)\n",
        "    for sentiment in sentiments:\n",
        "        entity = {'PartitionKey': 'sentiment', 'RowKey': str(uuid.uuid4()), 'Sentiment': sentiment}\n",
        "        table_service.insert_entity(table_name, entity)\n",
        "\n",
        "def main():\n",
        "    video_link = input('Enter Facebook video link: ')\n",
        "    comment_texts = get_facebook_video_comments(video_link)\n",
        "    sentiments = analyze_sentiment(comment_texts)\n",
        "    store_sentiments_in_cosmosdb(sentiments)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n",
        "response = text_analytics_client.analyze_sentiment(get_facebook_video_comments)\n",
        "\n",
        "for doc in response:\n",
        "    print(\"Overall sentiment: {}\".format(doc.sentiment))\n",
        "    print(\"Scores: positive={}, neutral={}, negative={}\\n\".format(\n",
        "        doc.confidence_scores.positive,\n",
        "        doc.confidence_scores.neutral,\n",
        "        doc.confidence_scores.negative,\n",
        "    ))\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, jaccard_score, f1_score,log_loss, mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Example ground truth and predicted language labels (replace with your actual data)\n",
        "actual_labels = [1, 0, 1, 0, 1]\n",
        "predicted_labels = [1, 0, 1, 0, 1]\n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy = accuracy_score(actual_labels, predicted_labels)\n",
        "print(f\"Accuracy Score: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate Jaccard index\n",
        "jaccard = jaccard_score(actual_labels, predicted_labels, average=\"weighted\")\n",
        "print(f\"Jaccard Index: {jaccard:.4f}\")\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(actual_labels, predicted_labels, average=\"weighted\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "y_true = np.array([1, 0, 1, 0, 1])\n",
        "y_pred_probs = np.array([0.9, 0.2, 0.8, 0.1, 0.95])\n",
        "\n",
        "# Calculate log loss\n",
        "logloss = log_loss(y_true, y_pred_probs)\n",
        "print(f\"Log Loss: {logloss:.4f}\")\n",
        "\n",
        "# Example ground truth and predicted values (replace with your actual data)\n",
        "y_true_regression = np.array([3, -0.5, 2, 7])\n",
        "y_pred_regression = np.array([2.5, 0.0, 2, 8])\n",
        "\n",
        "# Calculate MAE\n",
        "mae = mean_absolute_error(y_true_regression, y_pred_regression)\n",
        "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
        "\n",
        "# Calculate MSE\n",
        "mse = mean_squared_error(y_true_regression, y_pred_regression)\n",
        "print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "\n",
        "# Calculate R2-score\n",
        "r2 = r2_score(y_true_regression, y_pred_regression)\n",
        "print(f\"R2-Score: {r2:.4f}\")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'textblob'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_sentiment\u001b[39m(comment_texts):\n\u001b[1;32m      5\u001b[0m     sentiments \u001b[38;5;241m=\u001b[39m []\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1714969444084
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}